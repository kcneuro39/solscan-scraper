name: Solscan Scraper

on:
  schedule:
    - cron: '0 * * * *' # Runs every hour at minute 0
  workflow_dispatch: # Allows manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20' # Latest LTS version as of March 2025
          cache: 'npm' # Cache npm dependencies

      - name: Install dependencies
        run: npm ci # Use npm ci for faster, deterministic installs

      - name: Cache Puppeteer dependencies
        uses: actions/cache@v3
        with:
          path: /usr/lib # Cache system libraries
          key: ${{ runner.os }}-puppeteer-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-puppeteer-

      - name: Install Puppeteer dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libgbm-dev libatk-bridge2.0-0 libcups2-dev libxkbcommon-x11-0 libxcomposite-dev libxrandr-dev libxdamage-dev

      - name: Run Solscan scraper
        env:
          EMAIL_USER: ${{ secrets.EMAIL_USER }}
          EMAIL_PASS: ${{ secrets.EMAIL_PASS }}
        run: timeout 10m node extract-headless.js --no-sandbox --disable-gpu --disable-dev-shm-usage || echo "Script timed out after 10 minutes"